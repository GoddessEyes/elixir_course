# MapReduce

Мы теперь умеем создавать потоки и передавать информацию между ними. Давайте с их помощью решим практическую задачу.


## Что такое MapReduce?

Представьте, что у нас есть много данных. Настолько много, что они не помещаются на одном компьютере, и хранятся частями на нескольких компьютерах. Это один из аттрибутов ["больших данных" (Big Data)](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D0%B5_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5). Мы хотим эти данные не просто хранить, а извлекать из них какую-то пользу. Для этого нужно уметь как-то их обрабатывать.

Один из способов обработки больших данных -- [MapReduce](https://ru.wikipedia.org/wiki/MapReduce). Это модель распределенных вычислений над данными в кластере. Работа выполняется параллельно во много потоков на всех машинах одновременно. Название происходит от двух известных функций высшего порядка -- **map** и **reduce**. 

Потоки делятся по ролям на две группы. **Map-потоки** получают некую часть данных, вычисляют промежуточный результат над этими данными, и передают их в **Reduce-потоки**. Каждый Reduce-поток собирает результаты от нескольких Map-потоков и агрегирует их. Reduce-потоки могут быть организованы в древовидную иерархию, где потоки нижнего уровня являются источником данных для следущего уровня. В конечном итоге все данные агрегируются в вершине дерева. И это является результатом всех вычислений.

В модели еще нужен координатор, который создаст иерархию Reduce-потоков и распределит все данные между Map-потоками.

Одна из популярных реализаций модели MapReduce это [Apache Hadoop](https://hadoop.apache.org/).


## Задача

Наша задача -- посчитать суммарное количество слов в списке файлов. С этой задачай вполне справляется утилита **wc**:

```
$ wc -w 09_01_processes.md 09_02_mailbox.md 09_03_link.md 09_04_monitor.md
  872 09_01_processes.md
  644 09_02_mailbox.md
 1162 09_03_link.md
  325 09_04_monitor.md
 3003 total
```
Но wc работает последовательно в одном потоке. Мы же хотим ускорить вычисление и обработать все файлы одновременно. Поэтому мы запустим отдельный процесс для каждого файла. Это будет Map-процесс. Он прочитает файл с диска, разделит его на слова и посчитает количество слов. 

Затем нам нужны Reduce-процессы, чтобы собрать и суммировать данные от всех Map-процессов. Мы запустим дерево из трех Reduce-процессов: корневой и два дочерних. У каждого дочернего Reduce-процесса будет по два Map-процесса.

TODO -- нарисовать схему.
```
- root_reducer
  - r1 reducer
    - w1 mapper
    - w2 mapper
  - r2 reducer
    - w3 mapper
    - w4 mapper
```

Запускаем код:

```
iex(1)> c "09_05_map_reduce.exs"
iex(2)> alias Lesson_09.Task_05_Map_Reduce, as: T
iex(3)> T.start()
start reducer 'root_reducer' with childs [:r1, :r2]
start reducer 'r1' with childs [:w1, :w2]
start mapper 'w1' with file './09_01_processes.md'
start mapper 'w2' with file './09_02_mailbox.md'
start reducer 'r2' with childs [:w3, :w4]
start mapper 'w3' with file './09_03_link.md'
start mapper 'w4' with file './09_04_monitor.md'
reducer r1 got result 872 from w1
reducer r1 got result 644 from w2
reducer root_reducer got result 1516 from r1
reducer r2 got result 1162 from w3
reducer r2 got result 325 from w4
reducer root_reducer got result 1487 from r2
{:ok, 3003}
```

При таком количестве данных -- 4 небольших файла, последовательное выполнение в одном процессе может оказаться быстрее. Потому что в MapReduce системе есть накладные расходы на запуск процессов и копирование данных. Но с ростом данных на каком-то этапе MapReduce становится выгоднее. А когда данные не помещаются на одном компьютере и распределяются по кластеру, последовательная обработка точно проиграет распределенной обработке.
